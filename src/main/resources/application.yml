spring:
  application:
    name: langchan4j

server:
  port: 8080

langchain4j:
  open-ai:
    chat-model:
#      api-key:
#      model-name: deepseek-chat
#      log-requests: true
#      log-responses: true
#      base-url: https://api.deepseek.com/v1
      api-key:
      model-name: deepseek-v3
      log-requests: true
      log-responses: true
      base-url: https://dashscope.aliyuncs.com/compatible-mode/v1
  ollama:
    chat-model:
      model-name: deepseek-r1:1.5b
      log-requests: true
      log-responses: true
      base-url: http://localhost:11434
      timeout: PT60S
      temperature: 0.8
  community:
    dashscope:
      chat-model:
        api-key:
        model-name: qwen-max



